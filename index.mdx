---
title: "Welcome to Artemis RL Gym"
description: "Production-ready distributed reinforcement learning framework for Large Language Models"
---

<div align="center">

![Artemis RL Gym](/images/artemis-logo.png)

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Code Style: Black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

**A Production-Ready Distributed Reinforcement Learning Framework for Large Language Models**

[Get Started](/artemis/quickstart)
[View on GitHub](https://github.com/noema-research/artemis-rl-gym)

</div>

## What is Artemis RL Gym?

Artemis RL Gym is an enterprise-grade reinforcement learning framework specifically designed for training Large Language Models (LLMs) at scale. Built from the ground up for production environments, it combines cutting-edge RL algorithms with distributed computing capabilities to deliver unparalleled performance and reliability.

## Key Features

<CardGroup cols={2}>
<Card title="üöÄ Production-Ready" href="/artemis/introduction">
  Built for enterprise deployments with comprehensive monitoring and fault tolerance
</Card>

<Card title="üí∞ Zero-Cost Scaling" href="/artemis/distributed/overview">
  In-memory message broker eliminates Redis/RabbitMQ costs while maintaining full functionality
</Card>

<Card title="üß† LLM-Optimized" href="/artemis/core/agents">
  Native support for 50+ open-source models with intelligent detection and optimization
</Card>

<Card title="üåê Truly Distributed" href="/artemis/distributed/overview">
  Auto-scaling inference engines, environment orchestration, and fault-tolerant communication
</Card>
</CardGroup>

## Quick Start

Get up and running in minutes:

<CodeGroup>

```bash Install
pip install git+https://github.com/Noema-Research/ArtemisRL-Gym.git
```

```python Basic Training
import asyncio
from artemis import train_llm_grpo

async def main():
    results = await train_llm_grpo(
        model_name="microsoft/DialoGPT-medium",
        env_type="conversation",
        num_episodes=100,
        distributed=True
    )
    print(f"Training complete! Final reward: {results['final_reward']:.3f}")

asyncio.run(main())
```

</CodeGroup>

## What's Next?

<CardGroup cols={3}>
<Card title="üìö Full Documentation" href="/artemis/introduction">
  Complete guide to Artemis RL Gym features and capabilities
</Card>

<Card title="‚ö° Quick Start" href="/artemis/quickstart">
  Get training in under 10 minutes
</Card>

<Card title="üîß API Reference" href="/artemis/api-reference/introduction">
  Comprehensive API documentation
</Card>

<Card title="üí° Examples" href="/artemis/examples/overview">
  Practical tutorials and use cases
</Card>

<Card title="üèóÔ∏è Core Components" href="/artemis/core/overview">
  Learn about agents, environments, and algorithms
</Card>

<Card title="üåê Distributed Training" href="/artemis/distributed/overview">
  Scale across multiple nodes with fault tolerance
</Card>
</CardGroup>

## Community & Support

<CardGroup cols={2}>
<Card title="GitHub Repository" icon="github" href="https://github.com/noema-research/artemis-rl-gym">
  Source code, issues, and contributions
</Card>

<Card title="Discord Community" icon="discord" href="https://discord.gg/artemis-rl">
  Join our community for support and discussions
</Card>
</CardGroup>

---

<div align="center">

**Built with ‚ù§Ô∏è by Noema Research for the open-source community**

</div>